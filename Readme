EFTGAN:
we develop a generative network framework: Elemental Features enhanced and Transferring corrected data augmentation
in Generative Adversarial Networks (EFTGAN). Combining the elemental convolution technique with Generative Adversarial Networks (GAN),
EFTGAN provides a robust and efficient approach for generating data containing elemental and structural information that can be used not only
for data augmentation to improve model accuracy, but also for prediction when the structures are unknown. 
Applying this framework to the FeNiCoCrMn/Pd high-entropy alloys, we successfully improve the prediction accuracy
in a small data set and predict the concentrationdependent formation energies, lattices,
and magnetic moments in quinary systems. 

Contents of documents：
The folder HAE_Data contains all the data for the model.
The folder datasets contains the data loading datasets for the training of each model.
The folder models contains the network structure of each model.
MLP_transfer.py is for training the transfer augmentation model and predicted result.
get_ib.py is used to extract interaction blocks from the trained ECNe.
get_describer.py is used to downscale the interaction block.
model.py defines the generic class for the project's model.
model_test.py is the test file for model development.
trainer_agunet.py is used to train the augmentation model.
trainer_gan.py is used to train training InfoGAN models.
trainer_heanet.py is used to train ECNet with single task.
trainer_heanet_mtl_HEA.py is used to train ECNet with mult-task

Order:
python trainer_heanet_mtl_HEA.py --task etot emix eform --hidden_channels 128 --n_filters 64 --n_interactions 3 --is_validate --tower_h1 128 --tower_h2 64 --batch_size 128 --epochs 500 --split_type 0 -t
Training to get a model of IB
the score of task 0 is 0.07146676629781723

the score of task 1 is 0.028152920305728912

the score of task 2 is 0.03343312442302704


Order：
python getib.py --task etot emix eform --hidden_channels 128 --n_filters 64 --n_interactions 3 --is_validate --tower_h1 128 --tower_h2 64 --batch_size 1 --epochs 500 --processed_data --split_type 0 -p
Output IB save file, note call model

Order:
python trainer_agunet.py --task etot emix eform --hidden_channels 128 --n_filters 64 --n_interactions 3 --is_validate --tower_h1 128 --tower_h2 64 --batch_size 128 --epochs 800 --split_type 0 -t
Train the augmented model

Order:
python trainer_heanet_mtl_HEA.py --task eform --hidden_channels 128 --n_filters 64 --n_interactions 3 --tower_h1 128 --tower_h2 64 --batch_size 128 --epochs 500 --split_type 1 -p
predict
